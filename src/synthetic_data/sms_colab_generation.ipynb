{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SMS conversation generator using personas and relationships.\n",
    "Uses CAMEL-style multi-agent simulation with distilabel + vLLM (Qwen3).\n",
    "\n",
    "This notebook is for running in Google Colab.\n",
    "The code has been refactored into modular files:\n",
    "- config.py: Configuration constants\n",
    "- text_utils.py: Message cleaning and validation  \n",
    "- generator.py: Core generation logic\n",
    "\n",
    "For local usage, run: python -m src.synthetic_data.generator\n",
    "\"\"\"\n",
    "\n",
    "# Install dependencies (for Colab)\n",
    "# !pip install -q pydantic tqdm distilabel[vllm]\n",
    "\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================================================================\n",
    "# Configuration\n",
    "# =============================================================================\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "PERSONAS_FILE = DATA_DIR / \"personas.json\"\n",
    "RELATIONSHIPS_FILE = DATA_DIR / \"relationships.json\"\n",
    "OUTPUT_FILE = DATA_DIR / \"conversations.json\"\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "CONVERSATIONS_PER_RELATIONSHIP = {\n",
    "    \"partner\": 8,\n",
    "    \"close_friends\": 5,\n",
    "    \"friends\": 3,\n",
    "    \"family\": 4,\n",
    "    \"colleagues\": 3,\n",
    "    \"professionals\": 2,\n",
    "    \"businesses\": 2,\n",
    "    \"neighbors\": 2,\n",
    "    \"casual\": 2,\n",
    "    \"other\": 1,\n",
    "}\n",
    "\n",
    "TURN_RANGES = {\n",
    "    \"partner\": (8, 20),\n",
    "    \"close_friends\": (6, 15),\n",
    "    \"friends\": (4, 12),\n",
    "    \"family\": (4, 10),\n",
    "    \"colleagues\": (3, 8),\n",
    "    \"professionals\": (2, 6),\n",
    "    \"businesses\": (2, 4),\n",
    "    \"neighbors\": (2, 6),\n",
    "    \"casual\": (3, 8),\n",
    "    \"other\": (2, 6),\n",
    "}\n",
    "\n",
    "SCENARIO_TEMPLATES = {\n",
    "    \"partner\": [\n",
    "        \"Asking for help with something\",\n",
    "        \"Planning dinner tonight\",\n",
    "        \"Checking in during work day\",\n",
    "        \"Discussing weekend plans\",\n",
    "        \"Small argument about chores\",\n",
    "    ],\n",
    "    \"family\": [\n",
    "        \"Asking for help with something\",\n",
    "        \"Catching up after not talking for a few days\",\n",
    "        \"Planning a family gathering\",\n",
    "        \"Sharing news about a relative\",\n",
    "    ],\n",
    "    \"close_friends\": [\n",
    "        \"Making plans to hang out\",\n",
    "        \"Sharing gossip or news\",\n",
    "        \"Venting about work or life\",\n",
    "        \"Asking for help with something\",\n",
    "    ],\n",
    "    \"friends\": [\n",
    "        \"Casual catch-up\",\n",
    "        \"Sharing a meme or link\",\n",
    "        \"Making loose plans\",\n",
    "        \"Asking for advice\"\n",
    "    ],\n",
    "    \"colleagues\": [\n",
    "        \"Quick work question\",\n",
    "        \"Coordinating on a project\",\n",
    "        \"Office gossip\",\n",
    "        \"Asking for help with something\",\n",
    "    ],\n",
    "    \"professionals\": [\n",
    "        \"Scheduling an appointment\",\n",
    "        \"Following up on a service\",\n",
    "        \"Asking for a quote\",\n",
    "        \"Confirming arrival time\",\n",
    "    ],\n",
    "    \"businesses\": [\n",
    "        \"Confirming a reservation\",\n",
    "        \"Checking order status\",\n",
    "        \"Asking about hours or availability\",\n",
    "    ],\n",
    "    \"neighbors\": [\n",
    "        \"Asking about a package delivery\",\n",
    "        \"Noise complaint (polite)\",\n",
    "        \"Borrowing something\",\n",
    "    ],\n",
    "    \"casual\": [\n",
    "        \"Planning a group activity\",\n",
    "        \"Sharing hobby-related info\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "RELATIONSHIP_IDENTITIES = {\n",
    "    \"partner\": \"spouse/romantic partner (you live together, you're a couple)\",\n",
    "    \"close_friends\": \"close friend (you hang out often, very casual)\",\n",
    "    \"friends\": \"friend\",\n",
    "    \"family\": \"family member\",\n",
    "    \"colleagues\": \"coworker\",\n",
    "    \"professionals\": \"professional contact\",\n",
    "    \"businesses\": \"business/service\",\n",
    "    \"neighbors\": \"neighbor\",\n",
    "    \"casual\": \"acquaintance\",\n",
    "    \"other\": \"contact\",\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# Data Models\n",
    "# =============================================================================\n",
    "\n",
    "class Message(BaseModel):\n",
    "    sender_uuid: str\n",
    "    text: str\n",
    "    timestamp_offset_minutes: int\n",
    "\n",
    "\n",
    "class Conversation(BaseModel):\n",
    "    main_uuid: str\n",
    "    contact_uuid: str\n",
    "    relationship_type: str\n",
    "    messages: list[Message]\n",
    "    scenario: str\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Text Utilities\n",
    "# =============================================================================\n",
    "\n",
    "def clean_message(text: str) -> str:\n",
    "    \"\"\"Remove artifacts and fix common generation issues.\"\"\"\n",
    "    text = re.sub(r'(?:Best regards|Regards|Warm regards|Sincerely|With (?:love|gratitude|thanks)|Cheers),?\\s*[-‚Äì‚Äî]?\\s*\\w+.*$', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\s*[-‚Äì‚Äî]\\s*\\w+\\s*$', '', text)\n",
    "    text = re.sub(r'\\bName\\b', '', text)\n",
    "    text = re.sub(r'\\[.*?(?:Name|name).*?\\]', '', text)\n",
    "    text = re.sub(r'^(?:Dear|Hi|Hello|Hey)\\s+[\\w\\s]+,\\s*', '', text, flags=re.IGNORECASE)\n",
    "    text = ''.join(c for c in text if ord(c) < 128 or ord(c) > 0x1F600)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def check_message_quality(text: str, history: list[dict], rel_type: str) -> tuple[bool, str]:\n",
    "    \"\"\"Check if a generated message is acceptable.\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    if len(text.split()) > 35:\n",
    "        return False, \"too_long\"\n",
    "    if len(text.split()) < 2:\n",
    "        return False, \"too_short\"\n",
    "    \n",
    "    if rel_type in (\"partner\", \"close_friends\", \"friends\", \"family\"):\n",
    "        formal = [\"best regards\", \"sincerely\", \"warm regards\", \"respectfully\"]\n",
    "        if any(f in text_lower for f in formal):\n",
    "            return False, \"too_formal\"\n",
    "    \n",
    "    if history:\n",
    "        last_text = history[-1][\"text\"].lower()\n",
    "        \n",
    "        def get_phrases(t):\n",
    "            words = t.split()\n",
    "            return set(' '.join(words[i:i+3]) for i in range(len(words)-2))\n",
    "        \n",
    "        text_phrases = get_phrases(text_lower)\n",
    "        last_phrases = get_phrases(last_text)\n",
    "        \n",
    "        if text_phrases and last_phrases:\n",
    "            overlap = len(text_phrases & last_phrases)\n",
    "            if overlap >= 2:\n",
    "                return False, \"too_similar\"\n",
    "        \n",
    "        time_pattern = r'(?:at|in|around)\\s+\\d+'\n",
    "        text_times = re.findall(time_pattern, text_lower)\n",
    "        last_times = re.findall(time_pattern, last_text)\n",
    "        if text_times and text_times == last_times:\n",
    "            return False, \"repeated_time\"\n",
    "    \n",
    "    return True, \"\"\n",
    "\n",
    "\n",
    "def extract_key_phrases(text: str) -> set[str]:\n",
    "    \"\"\"Extract meaningful phrases from a message.\"\"\"\n",
    "    text = text.lower()\n",
    "    phrases = set(re.findall(r'(?:in|at|around)\\s+\\d+', text))\n",
    "    words = text.split()\n",
    "    for i in range(len(words) - 2):\n",
    "        phrases.add(' '.join(words[i:i+3]))\n",
    "    return phrases\n",
    "\n",
    "\n",
    "def should_end_conversation(history: list[dict]) -> bool:\n",
    "    \"\"\"Detect if conversation has naturally ended.\"\"\"\n",
    "    if len(history) < 3:\n",
    "        return False\n",
    "    \n",
    "    last_msgs = [m['text'].lower() for m in history[-4:]]\n",
    "    \n",
    "    bye_patterns = ['bye', 'see you', 'see ya', 'ttyl', 'later', 'talk soon', 'cya', 'gotta go']\n",
    "    if sum(1 for msg in last_msgs if any(p in msg for p in bye_patterns)) >= 2:\n",
    "        return True\n",
    "    \n",
    "    confirm_patterns = ['sounds good', 'perfect', 'got it', 'will do', 'see you then', 'üëç', 'üëå']\n",
    "    if sum(1 for msg in last_msgs if any(p in msg for p in confirm_patterns)) >= 2:\n",
    "        return True\n",
    "    \n",
    "    recent_text = ' '.join(last_msgs)\n",
    "    if len(re.findall(r'\\d+(?::\\d+)?\\s*(?:am|pm|AM|PM)', recent_text)) >= 3:\n",
    "        return True\n",
    "    \n",
    "    if len(history) >= 3:\n",
    "        all_phrases = []\n",
    "        for msg in history[-4:]:\n",
    "            all_phrases.extend(extract_key_phrases(msg['text']))\n",
    "        phrase_counts = Counter(all_phrases)\n",
    "        if any(count >= 3 for phrase, count in phrase_counts.items() if len(phrase) > 5):\n",
    "            return True\n",
    "    \n",
    "    if len(history) >= 4:\n",
    "        def get_content_words(text):\n",
    "            stopwords = {'the', 'a', 'an', 'is', 'are', 'was', 'to', 'in', 'on', 'at', 'and', 'or', 'i', 'you', 'your', 'my'}\n",
    "            return set(w for w in text.lower().split() if w not in stopwords and len(w) > 2)\n",
    "        \n",
    "        recent_words = [get_content_words(m['text']) for m in history[-4:]]\n",
    "        for i in range(len(recent_words) - 1):\n",
    "            if recent_words[i] and recent_words[i+1]:\n",
    "                overlap = len(recent_words[i] & recent_words[i+1]) / max(len(recent_words[i] | recent_words[i+1]), 1)\n",
    "                if overlap > 0.6 and i >= 1:\n",
    "                    prev_overlap = len(recent_words[i-1] & recent_words[i]) / max(len(recent_words[i-1] | recent_words[i]), 1)\n",
    "                    if prev_overlap > 0.5:\n",
    "                        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "def infer_sms_style(persona: dict) -> str:\n",
    "    \"\"\"Infer texting style from persona demographics.\"\"\"\n",
    "    age = persona.get(\"age\", 40)\n",
    "    education = persona.get(\"education_level\", \"\")\n",
    "    \n",
    "    traits = []\n",
    "    if age < 25:\n",
    "        traits.extend([\"lowercase\", \"heavy emoji use\", \"abbreviations (u, ur, rn, ngl)\", \"no punctuation\"])\n",
    "    elif age < 40:\n",
    "        traits.extend([\"casual\", \"occasional emoji\", \"some abbreviations\"])\n",
    "    elif age < 60:\n",
    "        traits.extend([\"proper sentences\", \"minimal emoji\", \"full words\"])\n",
    "    else:\n",
    "        traits.extend([\"formal\", \"complete sentences\", \"no emoji\", \"may sign off with name\"])\n",
    "    \n",
    "    if \"doctorate\" in education or \"masters\" in education:\n",
    "        traits.append(\"articulate vocabulary\")\n",
    "    \n",
    "    return \", \".join(traits)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Helper Functions\n",
    "# =============================================================================\n",
    "\n",
    "def get_turn_count(relationship_type: str) -> int:\n",
    "    \"\"\"Get random turn count based on relationship type.\"\"\"\n",
    "    min_t, max_t = TURN_RANGES.get(relationship_type, (3, 8))\n",
    "    return random.randint(min_t, max_t)\n",
    "\n",
    "\n",
    "def get_contact_identity(rel_type: str, service_type: str | None = None) -> str:\n",
    "    \"\"\"Get relationship description for prompt.\"\"\"\n",
    "    if service_type:\n",
    "        return f\"{service_type} (professional service)\"\n",
    "    return RELATIONSHIP_IDENTITIES.get(rel_type, \"contact\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Prompt Building\n",
    "# =============================================================================\n",
    "\n",
    "def build_prompt(persona: dict, is_main: bool, scenario: str, \n",
    "                 contact_identity: str, service_type: str | None, history: list[dict],\n",
    "                 turn_number: int = 0, total_turns: int = 10) -> tuple[list[dict], str]:\n",
    "    \"\"\"Build chat messages for LLM with prefix caching optimization.\"\"\"\n",
    "    style = infer_sms_style(persona)\n",
    "    persona_text = persona.get('professional_persona') if service_type and not is_main else persona.get('persona', '')\n",
    "    \n",
    "    name_match = re.match(r'^([A-Z][a-z]+)', persona_text)\n",
    "    first_name = name_match.group(1) if name_match else \"Person\"\n",
    "    \n",
    "    cache_key = f\"{persona.get('uuid', '')}_{is_main}\"\n",
    "    \n",
    "    near_end = turn_number >= total_turns - 2\n",
    "    ending_instruction = \"\\n6. WRAP UP: Send a brief closer and END the conversation.\" if near_end else \"\"\n",
    "    \n",
    "    recent_topics = \"\"\n",
    "    if history:\n",
    "        last_msg = history[-1]['text'].lower()\n",
    "        time_match = re.search(r'(?:in|at|around)\\s+\\d+', last_msg)\n",
    "        if time_match:\n",
    "            recent_topics = f\"\\nDO NOT REPEAT: '{time_match.group()}' - this was already said.\"\n",
    "    \n",
    "    system = f\"\"\"You are {first_name}.\n",
    "\n",
    "BACKGROUND: {persona_text[:200]}...\n",
    "\n",
    "TEXTING STYLE: {style}\n",
    "\n",
    "---\n",
    "You're texting your {contact_identity}.\n",
    "SITUATION: {scenario}\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. MAX 20 words. Real texts are SHORT.\n",
    "2. NO greetings or sign-offs\n",
    "3. NEVER repeat what was just said - move the conversation forward\n",
    "4. Use contractions (I'm, don't, gonna)\n",
    "5. Don't sign your name{ending_instruction}{recent_topics}\n",
    "\n",
    "Write ONLY the text message. Nothing else.\"\"\"\n",
    "\n",
    "    history_text = \"\\n\".join(\n",
    "        f\"{'You' if m['is_main'] == is_main else 'Them'}: {m['text']}\" \n",
    "        for m in history[-4:]\n",
    "    )\n",
    "    \n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": f\"{history_text or '(Start the conversation)'}\\n\\nYour text:\"}\n",
    "    ], cache_key\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Conversation Generation\n",
    "# =============================================================================\n",
    "\n",
    "def generate_conversations(personas: dict, relationships: list, llm, limit: int | None = None) -> list[Conversation]:\n",
    "    \"\"\"Generate all conversations with batched LLM calls.\"\"\"\n",
    "    convs = []\n",
    "    for rel in relationships[:limit]:\n",
    "        main = personas.get(rel[\"from_uuid\"])\n",
    "        contact = personas.get(rel[\"to_uuid\"])\n",
    "        if not main or not contact:\n",
    "            continue\n",
    "        \n",
    "        rel_type = rel[\"relationship_type\"]\n",
    "        service_type = rel.get(\"service_type\")\n",
    "        contact_identity = get_contact_identity(rel_type, service_type)\n",
    "        pair_key = f\"{main['uuid']}_{contact['uuid']}\"\n",
    "        \n",
    "        num_convs = CONVERSATIONS_PER_RELATIONSHIP.get(rel_type, 1)\n",
    "        available_scenarios = SCENARIO_TEMPLATES.get(rel_type, [\"General conversation\"])\n",
    "        \n",
    "        for conv_idx in range(num_convs):\n",
    "            scenario = available_scenarios[conv_idx % len(available_scenarios)]\n",
    "            if service_type:\n",
    "                scenario = f\"Contacting {service_type} - {scenario}\"\n",
    "            \n",
    "            convs.append({\n",
    "                \"main\": main,\n",
    "                \"contact\": contact,\n",
    "                \"rel_type\": rel_type,\n",
    "                \"scenario\": scenario,\n",
    "                \"service_type\": service_type,\n",
    "                \"contact_identity\": contact_identity,\n",
    "                \"turns\": get_turn_count(rel_type),\n",
    "                \"current_turn\": 0,\n",
    "                \"history\": [],\n",
    "                \"time_offset\": 0,\n",
    "                \"pair_key\": pair_key,\n",
    "            })\n",
    "    \n",
    "    convs.sort(key=lambda c: c[\"pair_key\"])\n",
    "    \n",
    "    total_messages = sum(c[\"turns\"] for c in convs)\n",
    "    max_turns = max(c[\"turns\"] for c in convs) if convs else 0\n",
    "    \n",
    "    print(f\"Total conversations: {len(convs)}\")\n",
    "    print(f\"Total messages to generate: {total_messages}\")\n",
    "    print(f\"Max turns per conversation: {max_turns}\")\n",
    "    print(f\"Unique persona pairs: {len(set(c['pair_key'] for c in convs))} (sorted for cache efficiency)\")\n",
    "    \n",
    "    pbar = tqdm(total=total_messages, desc=\"Generating SMS\", unit=\"msg\")\n",
    "    \n",
    "    for turn in range(max_turns):\n",
    "        active_convs = [(i, c) for i, c in enumerate(convs) if c[\"current_turn\"] < c[\"turns\"]]\n",
    "        if not active_convs:\n",
    "            break\n",
    "        \n",
    "        batch_data = []\n",
    "        for i, conv in active_convs:\n",
    "            if should_end_conversation(conv[\"history\"]):\n",
    "                conv[\"current_turn\"] = conv[\"turns\"]\n",
    "                continue\n",
    "            \n",
    "            is_main_turn = (conv[\"current_turn\"] % 2 == 0)\n",
    "            persona = conv[\"main\"] if is_main_turn else conv[\"contact\"]\n",
    "            \n",
    "            messages, cache_key = build_prompt(\n",
    "                persona, is_main_turn, conv[\"scenario\"],\n",
    "                conv[\"contact_identity\"], conv[\"service_type\"], conv[\"history\"],\n",
    "                turn_number=conv[\"current_turn\"], total_turns=conv[\"turns\"]\n",
    "            )\n",
    "            batch_data.append((messages, cache_key, i, is_main_turn))\n",
    "        \n",
    "        if not batch_data:\n",
    "            continue\n",
    "        \n",
    "        batch_data.sort(key=lambda x: x[1])\n",
    "        batch_inputs = [d[0] for d in batch_data]\n",
    "        batch_meta = [(d[2], d[3]) for d in batch_data]\n",
    "        \n",
    "        results = llm.generate(batch_inputs)\n",
    "        \n",
    "        retry_needed = []\n",
    "        for (i, is_main_turn), result in zip(batch_meta, results):\n",
    "            conv = convs[i]\n",
    "            text = result['generations'][0].strip().strip('\"').strip(\"'\")\n",
    "            text = clean_message(text)\n",
    "            \n",
    "            is_valid, issue = check_message_quality(text, conv[\"history\"], conv[\"rel_type\"])\n",
    "            if not is_valid:\n",
    "                retry_needed.append((i, is_main_turn, issue))\n",
    "                continue\n",
    "            \n",
    "            gap = random.randint(1, 15) if conv[\"rel_type\"] in (\"partner\", \"close_friends\") else random.randint(2, 60)\n",
    "            conv[\"time_offset\"] += gap\n",
    "            conv[\"history\"].append({\n",
    "                \"is_main\": is_main_turn,\n",
    "                \"sender_uuid\": conv[\"main\"][\"uuid\"] if is_main_turn else conv[\"contact\"][\"uuid\"],\n",
    "                \"text\": text,\n",
    "                \"timestamp_offset_minutes\": conv[\"time_offset\"],\n",
    "            })\n",
    "            conv[\"current_turn\"] += 1\n",
    "            pbar.update(1)\n",
    "        \n",
    "        if retry_needed:\n",
    "            retry_inputs = []\n",
    "            retry_meta = []\n",
    "            \n",
    "            for i, is_main_turn, issue in retry_needed:\n",
    "                conv = convs[i]\n",
    "                persona = conv[\"main\"] if is_main_turn else conv[\"contact\"]\n",
    "                \n",
    "                messages, _ = build_prompt(\n",
    "                    persona, is_main_turn, conv[\"scenario\"],\n",
    "                    conv[\"contact_identity\"], conv[\"service_type\"], conv[\"history\"],\n",
    "                    turn_number=conv[\"current_turn\"], total_turns=conv[\"turns\"]\n",
    "                )\n",
    "                messages[-1][\"content\"] += f\"\\n\\n(Be different. Previous was {issue}. Keep it SHORT and FRESH.)\"\n",
    "                retry_inputs.append(messages)\n",
    "                retry_meta.append((i, is_main_turn))\n",
    "            \n",
    "            if retry_inputs:\n",
    "                retry_results = llm.generate(retry_inputs)\n",
    "                \n",
    "                for (i, is_main_turn), result in zip(retry_meta, retry_results):\n",
    "                    conv = convs[i]\n",
    "                    text = result['generations'][0].strip().strip('\"').strip(\"'\")\n",
    "                    text = clean_message(text)\n",
    "                    \n",
    "                    gap = random.randint(1, 15) if conv[\"rel_type\"] in (\"partner\", \"close_friends\") else random.randint(2, 60)\n",
    "                    conv[\"time_offset\"] += gap\n",
    "                    conv[\"history\"].append({\n",
    "                        \"is_main\": is_main_turn,\n",
    "                        \"sender_uuid\": conv[\"main\"][\"uuid\"] if is_main_turn else conv[\"contact\"][\"uuid\"],\n",
    "                        \"text\": text,\n",
    "                        \"timestamp_offset_minutes\": conv[\"time_offset\"],\n",
    "                    })\n",
    "                    conv[\"current_turn\"] += 1\n",
    "                    pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    return [\n",
    "        Conversation(\n",
    "            main_uuid=c[\"main\"][\"uuid\"],\n",
    "            contact_uuid=c[\"contact\"][\"uuid\"],\n",
    "            relationship_type=c[\"rel_type\"],\n",
    "            scenario=c[\"scenario\"],\n",
    "            messages=[\n",
    "                Message(\n",
    "                    sender_uuid=m[\"sender_uuid\"],\n",
    "                    text=m[\"text\"],\n",
    "                    timestamp_offset_minutes=m[\"timestamp_offset_minutes\"]\n",
    "                )\n",
    "                for m in c[\"history\"]\n",
    "            ]\n",
    "        )\n",
    "        for c in convs\n",
    "    ]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Data I/O\n",
    "# =============================================================================\n",
    "\n",
    "def load_data() -> tuple[dict, list]:\n",
    "    \"\"\"Load personas and relationships from JSON files.\"\"\"\n",
    "    with open(PERSONAS_FILE) as f:\n",
    "        personas = json.load(f)\n",
    "    with open(RELATIONSHIPS_FILE) as f:\n",
    "        relationships = json.load(f)\n",
    "    return personas, relationships\n",
    "\n",
    "\n",
    "def save_conversations(conversations: list[Conversation], path: Path = OUTPUT_FILE):\n",
    "    \"\"\"Save conversations to JSON.\"\"\"\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump([c.model_dump() for c in conversations], f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Saved {len(conversations)} conversations to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61658284",
   "metadata": {},
   "outputs": [],
   "source": [
    "personas, relationships = load_data()\n",
    "print(f\"Loaded {len(personas)} personas and {len(relationships)} relationships\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distilabel.models import vLLM\n",
    "\n",
    "\n",
    "# Initialize vLLM with Qwen3 - optimized for T4 (16GB VRAM)\n",
    "llm = vLLM(\n",
    "    model=MODEL_NAME,\n",
    "    dtype=\"float16\",  # T4 doesn't support bfloat16 - must be top-level param\n",
    "    extra_kwargs={\n",
    "        # GPU settings\n",
    "        \"tensor_parallel_size\": 1,      # Single T4\n",
    "        \"gpu_memory_utilization\": 0.92, # Leave headroom for CUDA kernels\n",
    "        \n",
    "        # Memory optimization\n",
    "        \"max_model_len\": 2048,          # Reduce from 4096 - SMS are short\n",
    "        \"swap_space\": 0,                # Disable CPU swap\n",
    "        \"enforce_eager\": False,         # Use CUDA graphs (faster)\n",
    "        \n",
    "        # Batching optimization\n",
    "        \"max_num_seqs\": 64,             # Max concurrent sequences\n",
    "        \"enable_chunked_prefill\": True, # Better memory efficiency\n",
    "        \"enable_prefix_caching\": True,  # Cache common prefixes (system prompts)\n",
    "    },\n",
    "    generation_kwargs={\n",
    "        \"max_tokens\": 60,               # SMS are short - enforce brevity\n",
    "        \"temperature\": 0.9,             # Higher for more natural variation\n",
    "        \"top_p\": 0.95,\n",
    "        \"stop\": [\"\\n\\n\", \"Them:\", \"You:\", \"THEM:\", \"ME:\", \"Best regards\", \"Regards,\", \"Sincerely\"],\n",
    "    },\n",
    ")\n",
    "llm.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02129046",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Generating conversations for {len(relationships)} relationships...\")\n",
    "conversations = generate_conversations(personas, relationships, llm)\n",
    "save_conversations(conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabee5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sample conversations\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE CONVERSATIONS\")\n",
    "print(\"=\"*60)\n",
    "for conv in conversations[:3]:\n",
    "    print(f\"\\n{'‚îÄ'*50}\")\n",
    "    print(f\"üì± {conv.relationship_type.upper()} | {conv.scenario}\")\n",
    "    print(\"‚îÄ\" * 50)\n",
    "    for msg in conv.messages:\n",
    "        sender = \"‚Üí\" if msg.sender_uuid == conv.main_uuid else \"‚Üê\"\n",
    "        print(f\"  {sender} [{msg.timestamp_offset_minutes:3d}m] {msg.text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flspam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
